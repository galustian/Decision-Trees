{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(bi_split, classes):\n",
    "    # count all samples in both data-splits\n",
    "    n_datapoints = float(sum([len(g) for g in bi_split]))\n",
    "    \n",
    "    gini = 0.0\n",
    "    for group in bi_split:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        \n",
    "        score = 0.0\n",
    "        classes_amount = group.iloc[:, -1].value_counts()\n",
    "        for class_val in classes:\n",
    "            if len(classes_amount) == 1: continue\n",
    "            prop = classes_amount[class_val] / size\n",
    "            score += prop * (1 - prop)\n",
    "            \n",
    "        \n",
    "        # weight the group score by its relative size\n",
    "        gini += score * (size / n_datapoints)\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, df):\n",
    "    left_split = df[df[index] < value]\n",
    "    right_split = df[df[index] >= value]\n",
    "    return left_split, right_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates node with bi_split data\n",
    "def get_best_split(df, min_size):\n",
    "    class_values = df.iloc[:, -1].unique()\n",
    "    b_index, b_value, b_score, b_split= 999, 999, 999, None\n",
    "    \n",
    "    for index in range(df.shape[1]-1):\n",
    "        for i, row in df.iterrows():\n",
    "            # don't check gini_index for every split-size (too expensive)\n",
    "            # instead for every min_size'th row\n",
    "            if i % min_size != 0: continue\n",
    "            bi_split = test_split(index, row[index], df)\n",
    "            gini = gini_index(bi_split, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_split = index, row[index], gini, bi_split\n",
    "    \n",
    "    return {'index': b_index, 'value': b_value, 'bi_split': b_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_terminal(df_group):\n",
    "    return df_group.iloc[:, -1].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    # print(node['bi_split'])\n",
    "    left, right = node['bi_split']\n",
    "    del(node['bi_split'])\n",
    "    \n",
    "    # if either left or right df have length 0, then they are both the same class\n",
    "    # => you can't split them anymore => create terminal-node\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        node['left'] = node['right'] = to_terminal(left.append(right))\n",
    "        return\n",
    "        \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_best_split(left, min_size)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    \n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_best_split(right, min_size)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df_train, max_depth=7, min_size=5):\n",
    "    root = get_best_split(df_train, min_size)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print(\"{}[{} < {}]\".format(depth*' ', node['index'], node['value']))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print(\"{}, => {}\".format(depth*' ', node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('banknote.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:-125, :]\n",
    "df_test = df.iloc[-125:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(df_train, max_depth=5, min_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 1 , Expected: 1\n",
      "Predicted: 0 , Expected: 0\n",
      "Predicted: 1 , Expected: 1\n",
      "Error-rate: 0.984\n"
     ]
    }
   ],
   "source": [
    "size_test = len(df_test)\n",
    "correct = 0\n",
    "for i in range(len(df_test)):\n",
    "    predicted = predict(tree, df_test.iloc[i])\n",
    "    expected = df_test.iloc[i, -1]\n",
    "    if predicted == expected:\n",
    "        correct +=1\n",
    "    print(\"Predicted:\", predicted, \",\", \"Expected:\", expected)\n",
    "print(\"Error-rate:\", correct / size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
